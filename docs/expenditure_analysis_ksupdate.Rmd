---
title: "Model for Total Expenditures: Stubbs update"
date: "January 30, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


Below I've recreated the model generated by Kendon Stubbs as described in documents provided by Donna -- using the same 10 universities (minus UVA for the estimation) and independent variables to generate a model prediction for UVA.

```{r echo=FALSE, message=FALSE}
# load workspace
load("arl.Rdata")
library(scales)
library(tidyverse)

compare <- function(predicted, actual){
  cat("Predicted:", dollar(predicted), "\nActual:   ", dollar(actual))
  }

comparePlot <- function(model, predicted, actual){
  par(mfrow=c(1,2))
  mod.res <- resid(model)
  x1 <- actual - predicted
  hist(mod.res, breaks=15, xlab="Actual-Predicted Value", main="Histogram of Residuals", col="gray90")
  points(x1, 0, col="orange", pch=19)
  plot(mod.res, ylab="Actual-Predicted Value", main="Plot of Residuals")
  abline(h=0)
  points(x1, col="orange", pch=19)

}

ks <- c("CALIFORNIA, BERKELEY", "CORNELL", "DUKE", "EMORY", 
        "IOWA", "JOHNS HOPKINS", "MICHIGAN", "NORTH CAROLINA", 
        "PENNSYLVANIA")
arl_ks <- arl_us %>% filter(inam %in% ks)
project1 <- read_csv("project1.csv")
```

```{r}
mod_totexp_ks <- lm(totexp ~ fac + ugrad + gradstu + phdfld, 
                  data = arl_ks)
summary(mod_totexp_ks)
```

The estimated regression model is 
$$ 
\begin{align} 
Expenditures  = &`r dollar(mod_totexp_ks$coefficients[[1]], 1)` + `r dollar(mod_totexp_ks$coefficients[[2]], 1)` * faculty + `r dollar(mod_totexp_ks$coefficients[[3]], 1)` * undergraduates + \\ 
  & `r dollar(mod_totexp_ks$coefficients[[4]], 1)` * graduate~students + 
  `r dollar(mod_totexp_ks$coefficients[[5]], 1)` * PhD~fields 
\end{align}
$$

The model has a respectable  $R^2$ of `r round(summary(mod_totexp_ks)$adj.r.squared, 2)`, but only number of graduate students is marginally statistically significantly related to total expenditures. And the signifiance of the input variables collectively, that is, the significance of the overall model, is just at .05 (the p-value on the model F-statistic).

The UVA prediction for expenditures is above actual UVA expenditures in this case. But the selection of these nine comparison universities is a point of concern (and prone to criticisms of data drudging, or selecting a sample in order to achieve a desired result).

```{r}
pred_totexp <- predict(mod_totexp_ks, newdata = uva_totexp)
pred_totexp
compare(pred_totexp, uva_totexp$totexp)
comparePlot(mod_totexp_ks, pred_totexp, uva_totexp[["totexp"]])
```

Interestingly, this model doesn't generate predictions that differ notably from the 2% growth rate. Largely, this is a function of the fact that in the revised models I generated earlier, grants and endowments is carrying a disproporationate amount of the explanatory weight.

```{r echo=FALSE, include=FALSE}
pred_projks <- predict(mod_totexp_ks, newdata = project1, interval = "confidence")

pred0 <- bind_cols(year = rep(2017:2022, 2), 
                   projected = c(pred_projks[1:6], project1$totalks),
                   lwr = c(pred_projks[7:12], rep(NA, 6)), 
                   upr = c(pred_projks[13:18], rep(NA, 6)),
                   source = rep(c("model", "cap"), each = 6))

```

```{r}
ggplot(pred0, aes(y = projected, x = year, color = source)) + 
  geom_line() + 
  labs(title = "5-Year Expenditure Projections",
       subtitle = "Model-Based vs. 2% Cap")
```

